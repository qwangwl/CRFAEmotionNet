### CRFAEmotionNet

论文名称：A Two-Stream Channel Reconstruction and Feature Attention Network for EEG Emotion Recognition

对代码进行了简单的重构，以便于更加清晰明了的阅读。修改了一些简单的超参。以便于更好的实现。

对DEAP数据集的受试者独立和受试者依赖进行了实验。所进行实验建立在将受试者的影片进行了1s的窗口切分并进行打乱。

具体的，所进行实验结果如下表所示：

<center> 表1. 对DEAP数据集受试者独立进行的实验 </center>

| Emotion | ACC                 |
| ------- | ------------------- |
| valence | 0.98272$\pm$0.00124 |
| arousal | 0.98306$\pm$0.00168 |

<center>表2. 对DEAP数据集受试者依赖进行的实验</center>

| sub  | arousal            | valence            | sub  | arousal            | valence            |
| ---- | ------------------ | ------------------ | ---- | ------------------ | ------------------ |
| 1    | 0.9991666666666668 | 0.9995833333333334 | 17   | 0.9833333333333332 | 0.9833333333333334 |
| 2    | 0.9858333333333332 | 0.9920833333333334 | 18   | 0.9895833333333334 | 0.9916666666666668 |
| 3    | 0.9979166666666666 | 0.9954166666666667 | 19   | 0.9954166666666667 | 0.9941666666666666 |
| 4    | 0.9816666666666667 | 0.9829166666666665 | 20   | 0.9974999999999999 | 0.9958333333333333 |
| 5    | 0.99               | 0.9858333333333335 | 21   | 0.9974999999999999 | 0.9916666666666666 |
| 6    | 0.9916666666666668 | 0.99375            | 22   | 0.99               | 0.9854166666666666 |
| 7    | 0.9962500000000001 | 0.9979166666666666 | 23   | 0.9962500000000001 | 0.99875            |
| 8    | 0.9845833333333331 | 0.9833333333333334 | 24   | 0.9966666666666667 | 0.9925             |
| 9    | 0.9912500000000002 | 0.9933333333333334 | 25   | 0.9904166666666667 | 0.9887499999999999 |
| 10   | 0.9925             | 0.9958333333333333 | 26   | 0.9783333333333333 | 0.9841666666666666 |
| 11   | 0.9879166666666667 | 0.9875             | 27   | 0.9970833333333333 | 0.9974999999999999 |
| 12   | 0.9975000000000002 | 0.9858333333333335 | 28   | 0.9891666666666665 | 0.9883333333333335 |
| 13   | 0.9958333333333332 | 0.9958333333333332 | 29   | 0.9966666666666667 | 0.9966666666666667 |
| 14   | 0.9833333333333332 | 0.9837499999999999 | 30   | 0.9933333333333334 | 0.9966666666666667 |
| 15   | 0.9958333333333333 | 0.9929166666666667 | 31   | 0.9970833333333333 | 0.9979166666666668 |
| 16   | 0.9966666666666668 | 0.9962500000000001 | 32   | 0.9929166666666667 | 0.99375            |



此外，我们对SEED数据集进行了额外的实验，由于直接使用SEED数据集的原始信号会导致分类块的参数过多，我们仅使用了DE特征进行了简要的测试，此外，将窗口大小改成了1。

| session | acc                |
| ------- | ------------------ |
| 1       | 0.999901787468081  |
| 2       | 0.9999410724808486 |
| 3       | 0.9999803574936162 |

将所有影片切开再进行实验，准确率高的离谱了奥，主要原因还是在于同一个影片的样本高度相似。在某种程度上训练集见到了测试集的部分信息。

做完这几个实验，就懒得再改代码了。所以终结。

还是要往跨影片或者跨受试者发力。